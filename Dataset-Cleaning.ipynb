{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13de7659",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01d61293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    From  \\\n",
      "0       LeetCode <no-reply@leetcode.com>   \n",
      "1           \"Kohlâ€™s\" <Kohls@s.kohls.com>   \n",
      "2  Goibibo <noreply@content.goibibo.com>   \n",
      "3         SHEIN <shein@usmail.shein.com>   \n",
      "4           \"Kohlâ€™s\" <Kohls@s.kohls.com>   \n",
      "\n",
      "                                             Subject  \\\n",
      "0   $30 Off LeetCode Annual Premiumâ€”Starting Nov 25!   \n",
      "1  Save the date! Get up to 50% off beauty faves ...   \n",
      "2                         Bus cancelled = 2x refund!   \n",
      "3      The Secret's Out ðŸ‘€ Hot Picks are on Sale NOW!   \n",
      "4  Plot twist: Get Black Friday Deals TODAY ðŸ¤¯ Plu...   \n",
      "\n",
      "                              Date  \\\n",
      "0  Thu, 21 Nov 2024 17:08:42 +0000   \n",
      "1  Thu, 21 Nov 2024 10:44:52 -0600   \n",
      "2  Thu, 21 Nov 2024 19:21:03 +0530   \n",
      "3  Thu, 21 Nov 2024 17:07:35 +0100   \n",
      "4  Thu, 21 Nov 2024 04:11:35 -0600   \n",
      "\n",
      "                                                Body  \n",
      "0                                                NaN  \n",
      "1  https://click.s.kohls.com/?qs=caceafec6c57032e...  \n",
      "2  Goibibo \\r\\n\\r\\n Hereâ€™s how to claim this offe...  \n",
      "3                                                NaN  \n",
      "4  https://click.s.kohls.com/?qs=b0b020c5b3246c90...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('emails.csv')\n",
    "\n",
    "# Display the first few rows to understand the structure\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c276b488",
   "metadata": {},
   "source": [
    "# Understanding the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ba9b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 4 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   From     19999 non-null  object\n",
      " 1   Subject  19997 non-null  object\n",
      " 2   Date     20000 non-null  object\n",
      " 3   Body     16476 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 625.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check basic info\n",
    "print(df.info())\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afbfa12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From          1\n",
      "Subject       3\n",
      "Date          0\n",
      "Body       3524\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "print(df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "889c73e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check for duplicates\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f9a550",
   "metadata": {},
   "source": [
    "# Removing Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bd9c024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c9e2b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410c4464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicates\n",
    "print(f\"Number of duplicate rows: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200be938",
   "metadata": {},
   "source": [
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29560c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing essential information (e.g., 'From', 'Subject', 'Body')\n",
    "df = df.dropna(subset=['From', 'Subject', 'Body'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e113ca12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From       0\n",
      "Subject    0\n",
      "Date       0\n",
      "Body       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for null values\n",
    "print(df.isnull().sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6048d27c",
   "metadata": {},
   "source": [
    "# Standardizing and Cleaning Data - 'From' And 'Date' Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb3d3f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1                          \"Kohlâ€™s\" <Kohls@s.kohls.com>\n",
      "2                 Goibibo <noreply@content.goibibo.com>\n",
      "4                          \"Kohlâ€™s\" <Kohls@s.kohls.com>\n",
      "6                    Netflix <info@members.netflix.com>\n",
      "7                 Google Cloud <googlecloud@google.com>\n",
      "8                IndiGo <mailers@marketing.goindigo.in>\n",
      "9     \"CaratLane, A Tanishq Partnership\" <CaratLane@...\n",
      "11          Mirae Asset MF <noreply@miraeassetmf.co.in>\n",
      "12                    Temu <email@market.temuemail.com>\n",
      "13             Medium Daily Digest <noreply@medium.com>\n",
      "Name: From, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 values from the 'From' column\n",
    "print(df['From'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "049c9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Extract email addresses\n",
    "df['From'] = df['From'].apply(lambda x: re.findall(r'<(.+?)>', x)[0] if '<' in x else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c04c793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1                  Kohls@s.kohls.com\n",
      "2        noreply@content.goibibo.com\n",
      "4                  Kohls@s.kohls.com\n",
      "6           info@members.netflix.com\n",
      "7             googlecloud@google.com\n",
      "8      mailers@marketing.goindigo.in\n",
      "9     CaratLane@mailer.caratlane.com\n",
      "11        noreply@miraeassetmf.co.in\n",
      "12        email@market.temuemail.com\n",
      "13                noreply@medium.com\n",
      "Name: From, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 values from the 'From' column\n",
    "print(df['From'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "981c14fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1           Thu, 21 Nov 2024 10:44:52 -0600\n",
      "2           Thu, 21 Nov 2024 19:21:03 +0530\n",
      "4           Thu, 21 Nov 2024 04:11:35 -0600\n",
      "6           Thu, 21 Nov 2024 09:56:10 +0000\n",
      "7           Thu, 21 Nov 2024 01:43:02 -0800\n",
      "8           Thu, 21 Nov 2024 14:57:48 +0530\n",
      "9           Thu, 21 Nov 2024 09:04:48 +0000\n",
      "11          Thu, 21 Nov 2024 09:32:18 +0530\n",
      "12    Thu, 21 Nov 2024 04:11:54 +0000 (UTC)\n",
      "13    Thu, 21 Nov 2024 01:50:00 +0000 (UTC)\n",
      "Name: Date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 values from the 'Date' column\n",
    "print(df['Date'].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72aad1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date' to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "# Handle any remaining invalid dates\n",
    "df['Date'] = df['Date'].fillna(pd.Timestamp('1970-01-01'))  # Placeholder for invalid dates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d45290a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     2024-11-21 10:44:52-06:00\n",
      "2     2024-11-21 19:21:03+05:30\n",
      "4     2024-11-21 04:11:35-06:00\n",
      "6     2024-11-21 09:56:10+00:00\n",
      "7     2024-11-21 01:43:02-08:00\n",
      "8     2024-11-21 14:57:48+05:30\n",
      "9     2024-11-21 09:04:48+00:00\n",
      "11    2024-11-21 09:32:18+05:30\n",
      "12    2024-11-21 04:11:54+00:00\n",
      "13    2024-11-21 01:50:00+00:00\n",
      "Name: Date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 values from the 'Date' column\n",
    "print(df['Date'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041e2b03",
   "metadata": {},
   "source": [
    "# Cleaning Text Data - 'Subject' and 'Body' Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25e02fbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     Save the date! Get up to 50% off beauty faves ...\n",
      "2                            Bus cancelled = 2x refund!\n",
      "4     Plot twist: Get Black Friday Deals TODAY ðŸ¤¯ Plu...\n",
      "6     ðŸ”” Reminder: A Man on the Inside is now on Netflix\n",
      "7     Launch and learn with interactive, prebuilt so...\n",
      "8                We're celebrating Ethics Week with you\n",
      "9                       ðŸ“ˆ Trending this week: NEW RINGS\n",
      "11          ðŸš€ Launching: Mirae Asset Long Duration Fund\n",
      "12                           Your Purchase, Our Thanks!\n",
      "13    A Founder Who Just Raised a $3 Million Seed Ro...\n",
      "Name: Subject, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 values from the 'Subject' column - before cleaning\n",
    "print(df['Subject'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79e37b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     https://click.s.kohls.com/?qs=caceafec6c57032e...\n",
      "2     Goibibo \\r\\n\\r\\n Hereâ€™s how to claim this offe...\n",
      "4     https://click.s.kohls.com/?qs=b0b020c5b3246c90...\n",
      "6     Here's your reminder. Start watching now.\\r\\n\\...\n",
      "7     Google  \\r\\nCloudÂ­<https://notifications.googl...\n",
      "8     Share your thoughts and feedback so we can hon...\n",
      "9                                                     0\n",
      "11    <http://panela.miraeassetmf.co.in/vtrack?clien...\n",
      "12    ----------------------------------------------...\n",
      "13    Stories for Rishitha Pusapati\\r\\n@pusapatirish...\n",
      "Name: Body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 values from the 'Body' column - before cleaning\n",
    "print(df['Body'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4fb917",
   "metadata": {},
   "source": [
    "# a. Remove HTML Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd0e47f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove HTML Tags\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def remove_html(text):\n",
    "    return BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "df['Subject'] = df['Subject'].apply(remove_html)\n",
    "df['Body'] = df['Body'].apply(remove_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6aab0825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     Save the date! Get up to 50% off beauty faves ...\n",
      "2                            Bus cancelled = 2x refund!\n",
      "4     Plot twist: Get Black Friday Deals TODAY ðŸ¤¯ Plu...\n",
      "6     ðŸ”” Reminder: A Man on the Inside is now on Netflix\n",
      "7     Launch and learn with interactive, prebuilt so...\n",
      "8                We're celebrating Ethics Week with you\n",
      "9                       ðŸ“ˆ Trending this week: NEW RINGS\n",
      "11          ðŸš€ Launching: Mirae Asset Long Duration Fund\n",
      "12                           Your Purchase, Our Thanks!\n",
      "13    A Founder Who Just Raised a $3 Million Seed Ro...\n",
      "Name: Subject, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 values from the 'Date' column\n",
    "print(df['Subject'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a59873",
   "metadata": {},
   "source": [
    "# b. Remove URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79a152ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    return re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "df['Body'] = df['Body'].apply(remove_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0c1705",
   "metadata": {},
   "source": [
    "# c. Normalize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "566732e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to lower case,removing puntuation and tokenizing.\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text\n",
    "\n",
    "df['Body'] = df['Body'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ab7cc9",
   "metadata": {},
   "source": [
    "# d. Remove Stopwords and Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00fbbd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rajuk\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rajuk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\rajuk\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Eliminate common stopwords and lemmatize words for consistency.\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize text\n",
    "    words = text.split()\n",
    "    # Remove stopwords and lemmatize\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['Body'] = df['Body'].apply(preprocess_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "129d340d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1     plus stressfree holiday flawless gift set Í Í ...\n",
      "2     goibibo hereâ€™s claim offer follow u download g...\n",
      "4     save 85 clearance mark calendar sephora cyber ...\n",
      "6     here reminder start watching rish man inside 2...\n",
      "7     google cloudÂ­ deploy prebuilt google cloud sol...\n",
      "8     share thought feedback honour commitment view ...\n",
      "9                                                     0\n",
      "11                         click unsubscribe newsletter\n",
      "12    temu properly view full message content please...\n",
      "13    story rishitha pusapati pusapatirishitha98 Â·be...\n",
      "16    image google new signin window pusapatirishith...\n",
      "18    padma rishitha lifemiles number 00854153510 st...\n",
      "19    wait ðŸŽ‰ wishlist item back ready shine ðŸ¥³ â€Œâ€‹â€â€Žâ€ï»¿...\n",
      "21    gift guide part 2 â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ â€Œ ...\n",
      "22    cyclebar burbank 3820 w verdugo ave aburbank c...\n",
      "24    plus save 10 spice rest space Í Í Í Í Í Í Í Í ...\n",
      "25    tap know time takeitlite follow u download goi...\n",
      "26    jalebi learns faster peopleâ€”be mastering sweet...\n",
      "27    30 long weekend stay indigo ðŸ¨ view message htm...\n",
      "29    view web version unfortunately email client ca...\n",
      "Name: Body, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the first 10 values from the 'Body' column - after cleaning\n",
    "print(df['Body'].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a9b79b",
   "metadata": {},
   "source": [
    "# Explore the Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f070bc89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          From  \\\n",
      "1            Kohls@s.kohls.com   \n",
      "2  noreply@content.goibibo.com   \n",
      "4            Kohls@s.kohls.com   \n",
      "6     info@members.netflix.com   \n",
      "7       googlecloud@google.com   \n",
      "\n",
      "                                             Subject  \\\n",
      "1  Save the date! Get up to 50% off beauty faves ...   \n",
      "2                         Bus cancelled = 2x refund!   \n",
      "4  Plot twist: Get Black Friday Deals TODAY ðŸ¤¯ Plu...   \n",
      "6  ðŸ”” Reminder: A Man on the Inside is now on Netflix   \n",
      "7  Launch and learn with interactive, prebuilt so...   \n",
      "\n",
      "                        Date  \\\n",
      "1  2024-11-21 10:44:52-06:00   \n",
      "2  2024-11-21 19:21:03+05:30   \n",
      "4  2024-11-21 04:11:35-06:00   \n",
      "6  2024-11-21 09:56:10+00:00   \n",
      "7  2024-11-21 01:43:02-08:00   \n",
      "\n",
      "                                                Body  \n",
      "1  plus stressfree holiday flawless gift set Í Í ...  \n",
      "2  goibibo hereâ€™s claim offer follow u download g...  \n",
      "4  save 85 clearance mark calendar sephora cyber ...  \n",
      "6  here reminder start watching rish man inside 2...  \n",
      "7  google cloudÂ­ deploy prebuilt google cloud sol...  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16469"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the cleaned dataset\n",
    "print(df.head())\n",
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1158c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned dataset\n",
    "df.to_csv('cleaned_emails.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b8f5df",
   "metadata": {},
   "source": [
    "# Downloading the cleaned Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b1d1760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='cleaned_emails.csv' target='_blank'>cleaned_emails.csv</a><br>"
      ],
      "text/plain": [
       "C:\\Users\\rajuk\\Downloads\\Email Sentiment-NLP Project\\cleaned_emails.csv"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Create a download link\n",
    "FileLink('cleaned_emails.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176f2e32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
